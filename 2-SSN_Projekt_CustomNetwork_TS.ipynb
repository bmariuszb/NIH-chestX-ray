{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F41fm4vyr6uw"
      },
      "outputs": [],
      "source": [
        "!pip install deeplake[enterprise]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JknyZ8N4smL7",
        "outputId": "0eca5f48-17e7-45d1-f9f2-6c7fce777c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq8UOvW8sncg"
      },
      "outputs": [],
      "source": [
        "import deeplake\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpUQ7CI6sodb",
        "outputId": "51e2cb48-b402-4561-98bd-4f1f3ee57ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/nih-chest-xray-train\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "-"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/nih-chest-xray-train loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/nih-chest-xray-test\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/nih-chest-xray-test loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r\r \r"
          ]
        }
      ],
      "source": [
        "train_ds = deeplake.load('hub://activeloop/nih-chest-xray-train')\n",
        "test_ds = deeplake.load('hub://activeloop/nih-chest-xray-test')\n",
        "\n",
        "balanced_view = train_ds.query(\"select * sample by max_weight(contains(findings, 'Hernia'): 20, contains(findings, 'Pneumonia'): 8, contains(findings, 'Fibrosis'): 5, contains(findings, 'Edema'): 5, contains(findings, 'Emphysema'): 2, True: 1)\")\n",
        "\n",
        "train_ds, val_ds = train_ds.random_split([0.8, 0.2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lyjZ7aSsp7u",
        "outputId": "4226b205-6e73-47bc-ddc8-804c42eeb19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train dataset: 69220\n",
            "Size of validation dataset: 17304\n",
            "Size of test dataset: 25596\n"
          ]
        }
      ],
      "source": [
        "print(f'Size of train dataset: {len(train_ds)}')\n",
        "print(f'Size of validation dataset: {len(val_ds)}')\n",
        "print(f'Size of test dataset: {len(test_ds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3K0YaVWsrVi",
        "outputId": "80181190-4eae-4236-9b8b-aa4d2f28e8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 15\n",
            "0. No Finding\n",
            "1. Hernia\n",
            "2. Emphysema\n",
            "3. Nodule\n",
            "4. Pneumonia\n",
            "5. Consolidation\n",
            "6. Cardiomegaly\n",
            "7. Effusion\n",
            "8. Mass\n",
            "9. Pleural_Thickening\n",
            "10. Atelectasis\n",
            "11. Pneumothorax\n",
            "12. Fibrosis\n",
            "13. Infiltration\n",
            "14. Edema\n"
          ]
        }
      ],
      "source": [
        "classes_labels = train_ds.findings.info.class_names\n",
        "print(f'Number of classes: {len(classes_labels)}')\n",
        "for i, label in enumerate(classes_labels):\n",
        "  print(f'{i}. {label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXx05GFTssph"
      },
      "outputs": [],
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5]),\n",
        "])\n",
        "\n",
        "def findings_transform(findings_list):\n",
        "    multi_hot_encoded = [0] * len(classes_labels)\n",
        "    for index in findings_list:\n",
        "        multi_hot_encoded[index] = 1\n",
        "\n",
        "    return torch.Tensor(multi_hot_encoded)\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 2\n",
        "\n",
        "train_loader = train_ds.dataloader()\\\n",
        "                 .transform({'images': image_transform, 'findings': findings_transform})\\\n",
        "                 .batch(batch_size)\\\n",
        "                 .shuffle(False)\\\n",
        "                 .pytorch(num_workers = num_workers, decode_method={'images': 'pil'})\n",
        "\n",
        "val_loader = val_ds.dataloader()\\\n",
        "                 .transform({'images': image_transform, 'findings': findings_transform})\\\n",
        "                 .batch(batch_size)\\\n",
        "                 .shuffle(False)\\\n",
        "                 .pytorch(num_workers = num_workers, decode_method={'images': 'pil'})\n",
        "\n",
        "test_loader = test_ds.dataloader()\\\n",
        "                 .transform({'images': image_transform, 'findings': findings_transform})\\\n",
        "                 .batch(batch_size)\\\n",
        "                 .shuffle(False)\\\n",
        "                 .pytorch(num_workers = num_workers, decode_method={'images': 'pil'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qpy6f7Ffswze"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, threshold):\n",
        "  # Set the model to training mode.\n",
        "  model.train()\n",
        "\n",
        "  total_loss = 0.0\n",
        "  start_time = time.time()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for i, data in enumerate(data_loader):\n",
        "    inputs = data['images']\n",
        "    labels = data['findings']\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute binary predictions by thresholding the output probabilities.\n",
        "    predicted = (outputs > threshold).float()\n",
        "    # Calculate correctness of entire label vectors in the current batch\n",
        "    batch_correct = (predicted == labels).all(dim=1).float().sum().item()\n",
        "    # Update the total number of processed samples and correct samples.\n",
        "    total += labels.size(0)\n",
        "    correct += batch_correct\n",
        "\n",
        "    batch_loss = loss.item()\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if i % 100 == 0 and i > 0:\n",
        "      batch_time = time.time()\n",
        "      elapsed_time = batch_time - start_time\n",
        "      speed = total / elapsed_time\n",
        "      accuracy = 100 * correct / total\n",
        "      average_loss = total_loss / (i + 1)\n",
        "      print(f'[{i}]: Average loss so far: {average_loss:.4f}, Speed: {speed:.2f} Samples/s, Average accuracy so far: {accuracy:.2f}%')\n",
        "\n",
        "  average_loss = total_loss / len(data_loader)\n",
        "  print(f'Epoch completed. Average loss: {average_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iezLhS_Bs0Pr"
      },
      "outputs": [],
      "source": [
        "def test_model(model, data_loader, threshold):\n",
        "  model.eval()\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  last_10_correct = 0\n",
        "  last_10_total = 0\n",
        "\n",
        "  # Disable gradient calculation for faster evaluation\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(data_loader):\n",
        "      inputs = data['images']\n",
        "      labels = data['findings']\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Compute binary predictions by thresholding the output probabilities\n",
        "      predicted = (outputs > threshold).float()\n",
        "      # Calculate the number of correct predictions in the current batch\n",
        "      batch_correct = (predicted == labels).all(dim=1).float().sum().item()\n",
        "      # Calculate the total number of samples in the current batch\n",
        "      batch_total = labels.size(0)\n",
        "\n",
        "      correct += batch_correct\n",
        "      total += batch_total\n",
        "\n",
        "      last_10_correct += batch_correct\n",
        "      last_10_total += batch_total\n",
        "\n",
        "      if (i + 1) % 50 == 0 and i > 0:\n",
        "        last_10_accuracy = 100 * last_10_correct / last_10_total\n",
        "        average_accuracy = 100 * correct / total\n",
        "\n",
        "        print(f'[{i + 1}]: Last 50 batches accuracy: {last_10_accuracy:.2f}%, Average accuracy so far: {average_accuracy:.2f}%')\n",
        "\n",
        "        last_10_correct = 0\n",
        "        last_10_total = 0\n",
        "\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Finished Testing')\n",
        "  print(f'Testing accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cosnLaUZs1XK"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, epoch, save_path, model_name):\n",
        "  # Create the save directory if it doesn't exist\n",
        "  if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "  # Create the full path for the saved model\n",
        "  model_file = os.path.join(save_path, f\"{model_name}_epoch_{epoch}.pth\")\n",
        "\n",
        "  # Save the model and optimizer state_dicts\n",
        "  torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "  }, model_file)\n",
        "\n",
        "  print(f\"Model saved: {model_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model, optimizer, load_path, device):\n",
        "  # Load the saved model and optimizer state_dicts\n",
        "  checkpoint = torch.load(load_path)\n",
        "\n",
        "  # Load the model and optimizer state_dicts into the model and optimizer objects\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  # Move the model to the appropriate device (GPU or CPU)\n",
        "  model.to(device)\n",
        "\n",
        "  # Set the starting epoch for the model\n",
        "  start_epoch = checkpoint['epoch']\n",
        "\n",
        "  print(f\"Model loaded: {load_path}, starting from epoch {start_epoch}\")\n",
        "\n",
        "# Usage example:\n",
        "#load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/MultiLabelCNN_epoch_1.pth\"\n",
        "#load_model(model, optimizer, load_path, device)"
      ],
      "metadata": {
        "id": "TtBjedfRIm-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLabelCNN(nn.Module):\n",
        "    def __init__(self, num_labels=15):\n",
        "        super(MultiLabelCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, num_labels)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        # Max pooling is appliede 3 times\n",
        "        x = x.view(-1, 64 * 28 * 28)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "rBNOz-sxHXax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if GPU is available and setting the device accordingly\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Running on {device}')\n",
        "\n",
        "# Initialize the network and move it to the device\n",
        "model = MultiLabelCNN().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7WMWh95HmNS",
        "outputId": "6a336026-b885-48cb-837b-4b120dfb040a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "save_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models\" \n",
        "model_name = \"CustomNetwork\"\n",
        "\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    print(f'------------------ Training Epoch {epoch + 1} ------------------')\n",
        "    train_one_epoch(model, optimizer, train_loader, device, threshold=0.5)\n",
        "\n",
        "    save_model(model, optimizer, epoch+1, save_path, model_name)\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(model, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_p7949nHp4R",
        "outputId": "0266505e-7da4-4c36-f7b5-e5d902a328cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ Training Epoch 1 ------------------\n",
            "[100]: Average loss so far: 0.2076, Speed: 94.45 Samples/s, Average accuracy so far: 42.89%\n",
            "[200]: Average loss so far: 0.1984, Speed: 96.15 Samples/s, Average accuracy so far: 46.01%\n",
            "[300]: Average loss so far: 0.1967, Speed: 96.87 Samples/s, Average accuracy so far: 46.29%\n",
            "[400]: Average loss so far: 0.1960, Speed: 97.27 Samples/s, Average accuracy so far: 45.86%\n",
            "[500]: Average loss so far: 0.1949, Speed: 97.91 Samples/s, Average accuracy so far: 45.89%\n",
            "Epoch completed. Average loss: 0.1948\n",
            "Model saved: /content/drive/MyDrive/SSN_Projekt/Saved_Models/CustomNetwork_epoch_1.pth\n",
            "------------------ Training Epoch 2 ------------------\n",
            "[100]: Average loss so far: 0.1897, Speed: 98.00 Samples/s, Average accuracy so far: 48.33%\n",
            "[200]: Average loss so far: 0.1869, Speed: 100.14 Samples/s, Average accuracy so far: 48.86%\n",
            "[300]: Average loss so far: 0.1878, Speed: 100.73 Samples/s, Average accuracy so far: 48.30%\n",
            "[400]: Average loss so far: 0.1885, Speed: 100.77 Samples/s, Average accuracy so far: 47.31%\n",
            "[500]: Average loss so far: 0.1882, Speed: 100.85 Samples/s, Average accuracy so far: 47.13%\n",
            "Epoch completed. Average loss: 0.1883\n",
            "Model saved: /content/drive/MyDrive/SSN_Projekt/Saved_Models/CustomNetwork_epoch_2.pth\n",
            "------------------ Training Epoch 3 ------------------\n",
            "[100]: Average loss so far: 0.1867, Speed: 91.64 Samples/s, Average accuracy so far: 48.07%\n",
            "[200]: Average loss so far: 0.1840, Speed: 95.19 Samples/s, Average accuracy so far: 48.71%\n",
            "[300]: Average loss so far: 0.1849, Speed: 96.43 Samples/s, Average accuracy so far: 48.08%\n",
            "[400]: Average loss so far: 0.1856, Speed: 97.27 Samples/s, Average accuracy so far: 47.23%\n",
            "[500]: Average loss so far: 0.1854, Speed: 98.13 Samples/s, Average accuracy so far: 47.02%\n",
            "Epoch completed. Average loss: 0.1855\n",
            "Model saved: /content/drive/MyDrive/SSN_Projekt/Saved_Models/CustomNetwork_epoch_3.pth\n",
            "Finished Training\n",
            "------------------ Testing ------------------\n",
            "[50]: Last 50 batches accuracy: 17.92%, Average accuracy so far: 17.92%\n",
            "[100]: Last 50 batches accuracy: 16.81%, Average accuracy so far: 17.37%\n",
            "[150]: Last 50 batches accuracy: 13.89%, Average accuracy so far: 16.21%\n",
            "[200]: Last 50 batches accuracy: 31.80%, Average accuracy so far: 20.10%\n",
            "Finished Testing\n",
            "Testing accuracy: 20.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/CustomNetwork_epoch_1.pth\"\n",
        "load_model(model, optimizer, load_path, device)\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(model, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE4-XmyJIFY6",
        "outputId": "be48c23a-861f-4c93-f7f7-df96dafb4387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: /content/drive/MyDrive/SSN_Projekt/Saved_Models/CustomNetwork_epoch_1.pth, starting from epoch 1\n",
            "------------------ Testing ------------------\n",
            "[50]: Last 50 batches accuracy: 19.56%, Average accuracy so far: 19.56%\n",
            "[100]: Last 50 batches accuracy: 17.34%, Average accuracy so far: 18.45%\n",
            "[150]: Last 50 batches accuracy: 15.52%, Average accuracy so far: 17.47%\n",
            "[200]: Last 50 batches accuracy: 30.96%, Average accuracy so far: 20.84%\n",
            "Finished Testing\n",
            "Testing accuracy: 20.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/CustomNetwork_epoch_2.pth\"\n",
        "load_model(model, optimizer, load_path, device)\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(model, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFpJv8XRI8O7",
        "outputId": "6f4d7225-e9be-4e05-8f49-7a20762eedc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: /content/drive/MyDrive/SSN_Projekt/Saved_Models/CustomNetwork_epoch_2.pth, starting from epoch 2\n",
            "------------------ Testing ------------------\n",
            "[50]: Last 50 batches accuracy: 18.56%, Average accuracy so far: 18.56%\n",
            "[100]: Last 50 batches accuracy: 16.86%, Average accuracy so far: 17.71%\n",
            "[150]: Last 50 batches accuracy: 14.72%, Average accuracy so far: 16.71%\n",
            "[200]: Last 50 batches accuracy: 32.08%, Average accuracy so far: 20.55%\n",
            "Finished Testing\n",
            "Testing accuracy: 20.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Ym6iFqgI9au"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}