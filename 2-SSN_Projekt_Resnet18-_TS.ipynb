{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJLjfLhLr9Fv"
      },
      "outputs": [],
      "source": [
        "!pip install deeplake[enterprise]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTtX0jVcsGBe",
        "outputId": "ff6be636-667c-45d0-8077-2bf6653adf34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deeplake\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models"
      ],
      "metadata": {
        "id": "JLwE5rRHsH6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = deeplake.load('hub://activeloop/nih-chest-xray-train')\n",
        "test_ds = deeplake.load('hub://activeloop/nih-chest-xray-test')\n",
        "\n",
        "balanced_view = train_ds.query(\"select * sample by max_weight(contains(findings, 'Hernia'): 20, contains(findings, 'Pneumonia'): 8, contains(findings, 'Fibrosis'): 5, contains(findings, 'Edema'): 5, contains(findings, 'Emphysema'): 2, True: 1)\")\n",
        "\n",
        "train_ds, val_ds = train_ds.random_split([0.8, 0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGOHhIjtsJ30",
        "outputId": "bd3a9446-6751-496b-e01c-760b8a9ee18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/nih-chest-xray-train\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/nih-chest-xray-train loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/nih-chest-xray-test\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/nih-chest-xray-test loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r\r \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Size of train dataset: {len(train_ds)}')\n",
        "print(f'Size of validation dataset: {len(val_ds)}')\n",
        "print(f'Size of test dataset: {len(test_ds)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PESpP2k6sLZ7",
        "outputId": "4eb67613-d1e3-47d3-d5a0-e27403e6ec2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train dataset: 69220\n",
            "Size of validation dataset: 17304\n",
            "Size of test dataset: 25596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes_labels = train_ds.findings.info.class_names\n",
        "print(f'Number of classes: {len(classes_labels)}')\n",
        "for i, label in enumerate(classes_labels):\n",
        "  print(f'{i}. {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-XV-uYNsOG3",
        "outputId": "1acb54ed-8a59-4f0c-de82-849fbc505ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 15\n",
            "0. No Finding\n",
            "1. Hernia\n",
            "2. Emphysema\n",
            "3. Nodule\n",
            "4. Pneumonia\n",
            "5. Consolidation\n",
            "6. Cardiomegaly\n",
            "7. Effusion\n",
            "8. Mass\n",
            "9. Pleural_Thickening\n",
            "10. Atelectasis\n",
            "11. Pneumothorax\n",
            "12. Fibrosis\n",
            "13. Infiltration\n",
            "14. Edema\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5]),\n",
        "])\n",
        "\n",
        "def findings_transform(findings_list):\n",
        "    multi_hot_encoded = [0] * len(classes_labels)\n",
        "    for index in findings_list:\n",
        "        multi_hot_encoded[index] = 1\n",
        "\n",
        "    return torch.Tensor(multi_hot_encoded)\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 2\n",
        "\n",
        "train_loader = train_ds.dataloader()\\\n",
        "                 .transform({'images': image_transform, 'findings': findings_transform})\\\n",
        "                 .batch(batch_size)\\\n",
        "                 .shuffle(False)\\\n",
        "                 .pytorch(num_workers = num_workers, decode_method={'images': 'pil'})\n",
        "\n",
        "val_loader = val_ds.dataloader()\\\n",
        "                 .transform({'images': image_transform, 'findings': findings_transform})\\\n",
        "                 .batch(batch_size)\\\n",
        "                 .shuffle(False)\\\n",
        "                 .pytorch(num_workers = num_workers, decode_method={'images': 'pil'})\n",
        "\n",
        "test_loader = test_ds.dataloader()\\\n",
        "                 .transform({'images': image_transform, 'findings': findings_transform})\\\n",
        "                 .batch(batch_size)\\\n",
        "                 .shuffle(False)\\\n",
        "                 .pytorch(num_workers = num_workers, decode_method={'images': 'pil'})"
      ],
      "metadata": {
        "id": "q_tqh1_7sOvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, threshold):\n",
        "  # Set the model to training mode.\n",
        "  model.train()\n",
        "\n",
        "  total_loss = 0.0\n",
        "  start_time = time.time()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for i, data in enumerate(data_loader):\n",
        "    inputs = data['images']\n",
        "    labels = data['findings']\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute binary predictions by thresholding the output probabilities.\n",
        "    predicted = (outputs > threshold).float()\n",
        "    # Calculate correctness of entire label vectors in the current batch\n",
        "    batch_correct = (predicted == labels).all(dim=1).float().sum().item()\n",
        "    # Update the total number of processed samples and correct samples.\n",
        "    total += labels.size(0)\n",
        "    correct += batch_correct\n",
        "\n",
        "    batch_loss = loss.item()\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if i % 100 == 0 and i > 0:\n",
        "      batch_time = time.time()\n",
        "      elapsed_time = batch_time - start_time\n",
        "      speed = total / elapsed_time\n",
        "      accuracy = 100 * correct / total\n",
        "      average_loss = total_loss / (i + 1)\n",
        "      print(f'[{i}]: Average loss so far: {average_loss:.4f}, Speed: {speed:.2f} Samples/s, Average accuracy so far: {accuracy:.2f}%')\n",
        "\n",
        "  average_loss = total_loss / len(data_loader)\n",
        "  print(f'Epoch completed. Average loss: {average_loss:.4f}')"
      ],
      "metadata": {
        "id": "9R13YGhjsQNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, data_loader, threshold):\n",
        "  model.eval()\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  last_10_correct = 0\n",
        "  last_10_total = 0\n",
        "\n",
        "  # Disable gradient calculation for faster evaluation\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(data_loader):\n",
        "      inputs = data['images']\n",
        "      labels = data['findings']\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Compute binary predictions by thresholding the output probabilities\n",
        "      predicted = (outputs > threshold).float()\n",
        "      # Calculate the number of correct predictions in the current batch\n",
        "      batch_correct = (predicted == labels).all(dim=1).float().sum().item()\n",
        "      # Calculate the total number of samples in the current batch\n",
        "      batch_total = labels.size(0)\n",
        "\n",
        "      correct += batch_correct\n",
        "      total += batch_total\n",
        "\n",
        "      last_10_correct += batch_correct\n",
        "      last_10_total += batch_total\n",
        "\n",
        "      if (i + 1) % 50 == 0 and i > 0:\n",
        "        last_10_accuracy = 100 * last_10_correct / last_10_total\n",
        "        average_accuracy = 100 * correct / total\n",
        "\n",
        "        print(f'[{i + 1}]: Last 50 batches accuracy: {last_10_accuracy:.2f}%, Average accuracy so far: {average_accuracy:.2f}%')\n",
        "\n",
        "        last_10_correct = 0\n",
        "        last_10_total = 0\n",
        "\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Finished Testing')\n",
        "  print(f'Testing accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "1FPFOUxNsVgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, optimizer, epoch, save_path, model_name):\n",
        "  # Create the save directory if it doesn't exist\n",
        "  if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "  # Create the full path for the saved model\n",
        "  model_file = os.path.join(save_path, f\"{model_name}_epoch_{epoch}.pth\")\n",
        "\n",
        "  # Save the model and optimizer state_dicts\n",
        "  torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "  }, model_file)\n",
        "\n",
        "  print(f\"Model saved: {model_file}\")"
      ],
      "metadata": {
        "id": "p-cUzK-bsXoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model, optimizer, load_path, device):\n",
        "  # Load the saved model and optimizer state_dicts\n",
        "  checkpoint = torch.load(load_path)\n",
        "\n",
        "  # Load the model and optimizer state_dicts into the model and optimizer objects\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  # Move the model to the appropriate device (GPU or CPU)\n",
        "  model.to(device)\n",
        "\n",
        "  # Set the starting epoch for the model\n",
        "  start_epoch = checkpoint['epoch']\n",
        "\n",
        "  print(f\"Model loaded: {load_path}, starting from epoch {start_epoch}\")\n",
        "\n",
        "# Usage example:\n",
        "#load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/MultiLabelCNN_epoch_1.pth\"\n",
        "#load_model(model, optimizer, load_path, device)"
      ],
      "metadata": {
        "id": "D4V-EdMjsYz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modify the first layer to accept single channel (grayscale) images\n",
        "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the final layer to output multi-label probabilities using a Sigmoid activation function\n",
        "num_labels = 15\n",
        "resnet18.fc = nn.Sequential(\n",
        "    nn.Linear(resnet18.fc.in_features, num_labels),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Checking if GPU is available and setting the device accordingly\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Running on {device}')\n",
        "\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(resnet18.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT1unWOwscKO",
        "outputId": "11ede97c-6ce8-4cd1-a31d-0bdc943e44be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing the model\n",
        "num_epochs = 5\n",
        "save_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models\" \n",
        "model_name = \"Resnet18\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"------------------ Training Epoch {epoch + 1} ------------------\")\n",
        "    train_one_epoch(resnet18, optimizer, train_loader, device, threshold=0.5)\n",
        "\n",
        "    save_model(resnet18, optimizer, epoch + 1, save_path, model_name)\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(resnet18, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "id": "XpjcuK3OsiSw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "outputId": "ad43e6a6-2d70-40cc-93bf-5ee089f14bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ Training Epoch 1 ------------------\n",
            "[100]: Average loss so far: 0.2001, Speed: 110.14 Samples/s, Average accuracy so far: 46.69%\n",
            "[200]: Average loss so far: 0.1923, Speed: 111.96 Samples/s, Average accuracy so far: 46.65%\n",
            "[300]: Average loss so far: 0.1899, Speed: 112.69 Samples/s, Average accuracy so far: 46.31%\n",
            "[400]: Average loss so far: 0.1880, Speed: 112.85 Samples/s, Average accuracy so far: 46.46%\n",
            "[500]: Average loss so far: 0.1869, Speed: 113.11 Samples/s, Average accuracy so far: 46.33%\n",
            "Epoch completed. Average loss: 0.1866\n",
            "Model saved: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_1.pth\n",
            "------------------ Training Epoch 2 ------------------\n",
            "[100]: Average loss so far: 0.1754, Speed: 108.03 Samples/s, Average accuracy so far: 48.93%\n",
            "[200]: Average loss so far: 0.1758, Speed: 110.41 Samples/s, Average accuracy so far: 48.15%\n",
            "[300]: Average loss so far: 0.1765, Speed: 111.11 Samples/s, Average accuracy so far: 47.42%\n",
            "[400]: Average loss so far: 0.1762, Speed: 111.21 Samples/s, Average accuracy so far: 47.56%\n",
            "[500]: Average loss so far: 0.1763, Speed: 111.51 Samples/s, Average accuracy so far: 47.32%\n",
            "Epoch completed. Average loss: 0.1764\n",
            "Model saved: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_2.pth\n",
            "------------------ Training Epoch 3 ------------------\n",
            "[100]: Average loss so far: 0.1704, Speed: 109.48 Samples/s, Average accuracy so far: 49.33%\n",
            "[200]: Average loss so far: 0.1712, Speed: 111.27 Samples/s, Average accuracy so far: 48.55%\n",
            "[300]: Average loss so far: 0.1721, Speed: 112.23 Samples/s, Average accuracy so far: 47.81%\n",
            "[400]: Average loss so far: 0.1719, Speed: 112.43 Samples/s, Average accuracy so far: 47.97%\n",
            "[500]: Average loss so far: 0.1720, Speed: 112.57 Samples/s, Average accuracy so far: 47.77%\n",
            "Epoch completed. Average loss: 0.1722\n",
            "Model saved: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_3.pth\n",
            "------------------ Training Epoch 4 ------------------\n",
            "[100]: Average loss so far: 0.1668, Speed: 109.05 Samples/s, Average accuracy so far: 49.45%\n",
            "[200]: Average loss so far: 0.1674, Speed: 110.31 Samples/s, Average accuracy so far: 48.78%\n",
            "[300]: Average loss so far: 0.1683, Speed: 110.93 Samples/s, Average accuracy so far: 48.16%\n",
            "[400]: Average loss so far: 0.1680, Speed: 111.13 Samples/s, Average accuracy so far: 48.42%\n",
            "[500]: Average loss so far: 0.1681, Speed: 111.20 Samples/s, Average accuracy so far: 48.27%\n",
            "Epoch completed. Average loss: 0.1682\n",
            "Model saved: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_4.pth\n",
            "------------------ Training Epoch 5 ------------------\n",
            "[100]: Average loss so far: 0.1625, Speed: 108.61 Samples/s, Average accuracy so far: 49.90%\n",
            "[200]: Average loss so far: 0.1631, Speed: 110.91 Samples/s, Average accuracy so far: 49.40%\n",
            "[300]: Average loss so far: 0.1639, Speed: 111.61 Samples/s, Average accuracy so far: 48.70%\n",
            "[400]: Average loss so far: 0.1633, Speed: 111.68 Samples/s, Average accuracy so far: 48.93%\n",
            "[500]: Average loss so far: 0.1630, Speed: 111.83 Samples/s, Average accuracy so far: 48.93%\n",
            "Epoch completed. Average loss: 0.1631\n",
            "Model saved: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_5.pth\n",
            "Finished Training\n",
            "------------------ Testing ------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-81208cf875e6>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'------------------ Testing ------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: test_model() missing 1 required positional argument: 'device'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_1.pth\"\n",
        "load_model(resnet18, optimizer, load_path, device)\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(resnet18, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1IonsZAubu6",
        "outputId": "c6c57f60-6a6a-4d90-de5b-2ea5388d3a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_1.pth, starting from epoch 1\n",
            "------------------ Testing ------------------\n",
            "[50]: Last 50 batches accuracy: 14.94%, Average accuracy so far: 14.94%\n",
            "[100]: Last 50 batches accuracy: 16.17%, Average accuracy so far: 15.55%\n",
            "[150]: Last 50 batches accuracy: 13.09%, Average accuracy so far: 14.73%\n",
            "[200]: Last 50 batches accuracy: 31.72%, Average accuracy so far: 18.98%\n",
            "Finished Testing\n",
            "Testing accuracy: 18.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_2.pth\"\n",
        "load_model(resnet18, optimizer, load_path, device)\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(resnet18, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44YW2rIu-F_k",
        "outputId": "2ed80bd6-ca62-4811-e2d8-435d7bfc813d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_2.pth, starting from epoch 2\n",
            "------------------ Testing ------------------\n",
            "[50]: Last 50 batches accuracy: 16.09%, Average accuracy so far: 16.09%\n",
            "[100]: Last 50 batches accuracy: 17.22%, Average accuracy so far: 16.66%\n",
            "[150]: Last 50 batches accuracy: 14.11%, Average accuracy so far: 15.81%\n",
            "[200]: Last 50 batches accuracy: 32.16%, Average accuracy so far: 19.89%\n",
            "Finished Testing\n",
            "Testing accuracy: 19.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_3.pth\"\n",
        "load_model(resnet18, optimizer, load_path, device)\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(resnet18, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CISF77P_-GRp",
        "outputId": "42b3996e-719e-4be1-9d75-794fd84760e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_3.pth, starting from epoch 3\n",
            "------------------ Testing ------------------\n",
            "[50]: Last 50 batches accuracy: 18.00%, Average accuracy so far: 18.00%\n",
            "[100]: Last 50 batches accuracy: 18.52%, Average accuracy so far: 18.26%\n",
            "[150]: Last 50 batches accuracy: 15.39%, Average accuracy so far: 17.30%\n",
            "[200]: Last 50 batches accuracy: 33.97%, Average accuracy so far: 21.47%\n",
            "Finished Testing\n",
            "Testing accuracy: 21.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_4.pth\"\n",
        "load_model(resnet18, optimizer, load_path, device)\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(resnet18, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg2VZYil-Gbk",
        "outputId": "625cfdb6-20ee-4c06-dfa6-93712476b550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_4.pth, starting from epoch 4\n",
            "------------------ Testing ------------------\n",
            "[50]: Last 50 batches accuracy: 19.02%, Average accuracy so far: 19.02%\n",
            "[100]: Last 50 batches accuracy: 19.28%, Average accuracy so far: 19.15%\n",
            "[150]: Last 50 batches accuracy: 15.72%, Average accuracy so far: 18.01%\n",
            "[200]: Last 50 batches accuracy: 33.58%, Average accuracy so far: 21.90%\n",
            "Finished Testing\n",
            "Testing accuracy: 21.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_5.pth\"\n",
        "load_model(resnet18, optimizer, load_path, device)\n",
        "\n",
        "print(f'------------------ Testing ------------------')\n",
        "test_model(resnet18, test_loader, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYYp8Esy-Gjq",
        "outputId": "51ea64fe-4914-4352-e1d6-2c1f4db66cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: /content/drive/MyDrive/SSN_Projekt/Saved_Models/Resnet18_epoch_5.pth, starting from epoch 5\n",
            "------------------ Testing ------------------\n",
            "[50]: Last 50 batches accuracy: 21.42%, Average accuracy so far: 21.42%\n",
            "[100]: Last 50 batches accuracy: 21.66%, Average accuracy so far: 21.54%\n",
            "[150]: Last 50 batches accuracy: 18.20%, Average accuracy so far: 20.43%\n",
            "[200]: Last 50 batches accuracy: 34.94%, Average accuracy so far: 24.05%\n",
            "Finished Testing\n",
            "Testing accuracy: 24.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U50zorOWDkiK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}