{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description\n",
        "Comparison of classification accuracy for three dog breeds - Golden Retriever, Norwegian Elkhound, and Siberian Husky - using both neural network training from scratch and transfer learning. The images used are part of the [stanford dogs dataset](https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset), which contains information on 120 dog breeds.\n",
        "## 1. Requeired imports"
      ],
      "metadata": {
        "id": "w1EOtigSYJxE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lN_YNnSV6GW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparing data"
      ],
      "metadata": {
        "id": "4Xfaqn8fYYNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Checking if GPU is avalaible."
      ],
      "metadata": {
        "id": "RQv0uM7ZdLb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT4DKqaxdOFS",
        "outputId": "013dccfb-95be-4afc-e071-75558609752d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Defining transformations that will be applied to each given image."
      ],
      "metadata": {
        "id": "SjnMM0ZKZXN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "HLqRuYW0YWFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Defining sizes of train, validation and test datasets."
      ],
      "metadata": {
        "id": "FhZiUnDvZdo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = torchvision.datasets.ImageFolder(\n",
        "    root='/content/drive/MyDrive/Data/dogs/images',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "labels = [label for _, label in full_dataset]\n",
        "\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(train_ratio * total_size)\n",
        "val_size = int(val_ratio * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "print(f'Total size: {total_size}, train size: {train_size}, val_size: {val_size}, test_size: {test_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExeoBlpRYk9b",
        "outputId": "34537987-40e9-4faa-ffff-2f34422d4b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size: 538, train size: 430, val_size: 53, test_size: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Splitting dataset randomly into train, validation and test datasets."
      ],
      "metadata": {
        "id": "eV7NIlDsZw27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = 16\n",
        "shuffle = True\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)"
      ],
      "metadata": {
        "id": "QbiIsm9mZQxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Neural Network model from scratch\n",
        "1. Defining the model used for dog breed classification."
      ],
      "metadata": {
        "id": "XlYfhPtnaChl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DogClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DogClassifier, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 3)  # Change the output dimension to 3 for 3 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(nn.functional.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(nn.functional.relu(self.bn3(self.conv3(x))))\n",
        "        \n",
        "        x = x.view(-1, 128 * 28 * 28)\n",
        "        x = self.dropout(x)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "wkcXYw1bZ8ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Initializing defined model."
      ],
      "metadata": {
        "id": "wa_wLQA5aNHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = DogClassifier().to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "trNzTY1ZaIS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Training created model."
      ],
      "metadata": {
        "id": "oxyzInACaT18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = 0.0  # Initialize the best validation accuracy\n",
        "patience = 5  # Number of epochs to wait for an improvement in validation accuracy\n",
        "epochs_since_improvement = 0  # Initialize the counter for epochs without improvement\n",
        "epoch = 0  # Initialize the epoch counter\n",
        "\n",
        "while epochs_since_improvement < patience:\n",
        "  epoch += 1  # Increment the epoch counter\n",
        "\n",
        "    # Training\n",
        "  net.train()\n",
        "  train_loss = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = net(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "\n",
        "  # Validation\n",
        "  net.eval()\n",
        "  val_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      outputs = net(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      val_loss += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  val_loss /= len(val_loader)\n",
        "  val_acc = 100 * correct / total\n",
        "\n",
        "  print('Epoch: {}, Train Loss: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.2f}%, Best Val Accuracy: {:.2f}%'\n",
        "          .format(epoch, train_loss, val_loss, val_acc, best_val_acc))\n",
        "\n",
        "  # Check if validation accuracy has improved\n",
        "  if val_acc > best_val_acc:\n",
        "    best_val_acc = val_acc\n",
        "    epochs_since_improvement = 0\n",
        "  else:\n",
        "    epochs_since_improvement += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BTOZdsmaQKQ",
        "outputId": "f9248012-134f-473d-86ad-4deb963edc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 1.0866, Val Loss: 1.0428, Val Accuracy: 39.62%, Best Val Accuracy: 0.00%\n",
            "Epoch: 2, Train Loss: 1.0077, Val Loss: 0.9670, Val Accuracy: 67.92%, Best Val Accuracy: 39.62%\n",
            "Epoch: 3, Train Loss: 0.9433, Val Loss: 0.8760, Val Accuracy: 75.47%, Best Val Accuracy: 67.92%\n",
            "Epoch: 4, Train Loss: 0.8528, Val Loss: 0.7691, Val Accuracy: 69.81%, Best Val Accuracy: 75.47%\n",
            "Epoch: 5, Train Loss: 0.8153, Val Loss: 0.7016, Val Accuracy: 71.70%, Best Val Accuracy: 75.47%\n",
            "Epoch: 6, Train Loss: 0.7753, Val Loss: 0.7883, Val Accuracy: 58.49%, Best Val Accuracy: 75.47%\n",
            "Epoch: 7, Train Loss: 0.6903, Val Loss: 0.7168, Val Accuracy: 66.04%, Best Val Accuracy: 75.47%\n",
            "Epoch: 8, Train Loss: 0.6311, Val Loss: 0.6055, Val Accuracy: 71.70%, Best Val Accuracy: 75.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Evaluating trained model"
      ],
      "metadata": {
        "id": "KPkMeibZkBe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "all_labels = np.array([], dtype=int)\n",
        "all_predictions = np.array([], dtype=int)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Move tensors back to CPU and convert to NumPy arrays\n",
        "        cpu_labels = labels.cpu().numpy()\n",
        "        cpu_predicted = predicted.cpu().numpy()\n",
        "\n",
        "        all_labels = np.concatenate((all_labels, cpu_labels))\n",
        "        all_predictions = np.concatenate((all_predictions, cpu_predicted))\n",
        "\n",
        "test_acc = 100 * test_correct / test_total\n",
        "print('Test Accuracy: {:.2f}%'.format(test_acc))\n",
        "\n",
        "# Compute and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "conf_matrix_display = ConfusionMatrixDisplay(conf_matrix)\n",
        "conf_matrix_display.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "lToEeFG6aWDN",
        "outputId": "d68d39ce-202b-44ab-bb64-6fb37ab04604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 72.73%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f56c7618e50>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Using Transfer learning"
      ],
      "metadata": {
        "id": "AEuz6IJ0jMC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resnet18** is a convolutional neural network that is 18 layers deep. The network is trained on more than a million images from the ImageNet database. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. As a result, the network has learned rich feature representations for a wide range of images. The network has an image input size of 224-by-224."
      ],
      "metadata": {
        "id": "12EeXi4uY8QJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Architecture of the Resnet18 model in PyTorch."
      ],
      "metadata": {
        "id": "niWN5lUbaXrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "print(resnet18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnvR9oTMaVMU",
        "outputId": "108fadc0-8d40-4dfd-8359-f2dc67b5948d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Initialize pre-trained model."
      ],
      "metadata": {
        "id": "FSPJJ5FdjbUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the last fully connected layer\n",
        "no_features = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(no_features, 3)  # Change the output layer to have 3 classes - 1000 previously\n",
        "\n",
        "# Unfreeze the last few layers for fine-tuning\n",
        "unfreeze_from = \"layer4\"  # unfreeze from this layer onwards\n",
        "\n",
        "for name, param in resnet18.named_parameters():\n",
        "  if name.startswith(unfreeze_from):\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Move the model to a specified device, which can be a CPU or a GPU.\n",
        "resnet18.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Compute gradient only for unfreezed layers \n",
        "trainable_params = [param for param in resnet18.parameters() if param.requires_grad]\n",
        "optimizer = torch.optim.SGD(trainable_params, lr=0.001)"
      ],
      "metadata": {
        "id": "XLVGif6fi-HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Architecture of the Resnet18 model in PyTorch after changes."
      ],
      "metadata": {
        "id": "sF3hJsZEjhD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(resnet18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emHAzfcpdqgM",
        "outputId": "aba7fe99-a7b0-4956-d25b-bf88bbc9754f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Train the model to classify dogs breeds."
      ],
      "metadata": {
        "id": "fmF9TEWMd7Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = 0.0  # Initialize the best validation accuracy\n",
        "patience = 5  # Number of epochs to wait for an improvement in validation accuracy\n",
        "epochs_since_improvement = 0  # Initialize the counter for epochs without improvement\n",
        "epoch = 0  # Initialize the epoch counter\n",
        "\n",
        "while epochs_since_improvement < patience:\n",
        "  epoch += 1\n",
        "\n",
        "  # Training\n",
        "  resnet18.train()\n",
        "  train_loss = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = resnet18(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "  \n",
        "  train_loss /= len(train_loader)\n",
        "\n",
        "  # Validation\n",
        "  resnet18.eval()\n",
        "  val_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      outputs = resnet18(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      val_loss += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  val_loss /= len(val_loader)\n",
        "  val_acc = 100 * correct / total\n",
        "\n",
        "  print('Epoch: {}, Train Loss: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.2f}%, Best Val Accuracy: {:.2f}%'\n",
        "        .format(epoch, train_loss, val_loss, val_acc, best_val_acc))\n",
        "\n",
        "  # Check if validation accuracy has improved\n",
        "  if val_acc > best_val_acc:\n",
        "    best_val_acc = val_acc\n",
        "    epochs_since_improvement = 0\n",
        "  else:\n",
        "    epochs_since_improvement += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hxgLWKTjf7C",
        "outputId": "4c41af09-1eca-4295-d1b6-9174597a8d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 1.1070, Val Loss: 0.8451, Val Accuracy: 62.26%, Best Val Accuracy: 0.00%\n",
            "Epoch: 2, Train Loss: 0.7835, Val Loss: 0.6277, Val Accuracy: 77.36%, Best Val Accuracy: 62.26%\n",
            "Epoch: 3, Train Loss: 0.6197, Val Loss: 0.5302, Val Accuracy: 84.91%, Best Val Accuracy: 77.36%\n",
            "Epoch: 4, Train Loss: 0.4985, Val Loss: 0.4186, Val Accuracy: 90.57%, Best Val Accuracy: 84.91%\n",
            "Epoch: 5, Train Loss: 0.4270, Val Loss: 0.3866, Val Accuracy: 92.45%, Best Val Accuracy: 90.57%\n",
            "Epoch: 6, Train Loss: 0.3678, Val Loss: 0.3090, Val Accuracy: 94.34%, Best Val Accuracy: 92.45%\n",
            "Epoch: 7, Train Loss: 0.3250, Val Loss: 0.3172, Val Accuracy: 94.34%, Best Val Accuracy: 94.34%\n",
            "Epoch: 8, Train Loss: 0.3141, Val Loss: 0.3013, Val Accuracy: 96.23%, Best Val Accuracy: 94.34%\n",
            "Epoch: 9, Train Loss: 0.2776, Val Loss: 0.2756, Val Accuracy: 96.23%, Best Val Accuracy: 96.23%\n",
            "Epoch: 10, Train Loss: 0.2603, Val Loss: 0.2253, Val Accuracy: 96.23%, Best Val Accuracy: 96.23%\n",
            "Epoch: 11, Train Loss: 0.2336, Val Loss: 0.2293, Val Accuracy: 96.23%, Best Val Accuracy: 96.23%\n",
            "Epoch: 12, Train Loss: 0.2107, Val Loss: 0.1980, Val Accuracy: 96.23%, Best Val Accuracy: 96.23%\n",
            "Epoch: 13, Train Loss: 0.2061, Val Loss: 0.1901, Val Accuracy: 96.23%, Best Val Accuracy: 96.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Definig train sizes "
      ],
      "metadata": {
        "id": "E-zXXnqSjt5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "all_labels = np.array([], dtype=int)\n",
        "all_predictions = np.array([], dtype=int)\n",
        "\n",
        "with torch.no_grad():\n",
        "  # Test\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = resnet18(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    test_total += labels.size(0)\n",
        "    test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    cpu_labels = labels.cpu().numpy()\n",
        "    cpu_predicted = predicted.cpu().numpy()\n",
        "\n",
        "    all_labels = np.concatenate((all_labels, cpu_labels))\n",
        "    all_predictions = np.concatenate((all_predictions, cpu_predicted))\n",
        "\n",
        "test_acc = 100 * test_correct / test_total\n",
        "print('Test Accuracy: {:.2f}%'.format(test_acc))\n",
        "\n",
        "# Compute and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "conf_matrix_display = ConfusionMatrixDisplay(conf_matrix)\n",
        "conf_matrix_display.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "ITDGZP4Fjp9u",
        "outputId": "bb7a4b7b-9f5d-4d97-b9d0-d3f6745bfb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 94.55%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f56c71e4e80>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}